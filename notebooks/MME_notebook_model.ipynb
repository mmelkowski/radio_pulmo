{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Notebook de Model`\n",
    "\n",
    "Notebook de Mickael MELKOWSKI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Config`\n",
    "\n",
    "### `Import`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from random import shuffle\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# check for GPU support\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "# chemin relatif vers le dossier data\n",
    "home = pathlib.Path(\"../\")\n",
    "path_to_data = pathlib.Path(\"../data\")\n",
    "\n",
    "data_folder_path = path_to_data / \"raw\" / \"COVID-19_Radiography_Dataset\"\n",
    "output_path = path_to_data / \"processed\" / \"covid_19_masked_tiny_500\"\n",
    "folder_to_process = [\"Lung_Opacity\",\"COVID\",\"Normal\",\"Viral_Pneumonia\"]\n",
    "\n",
    "# model save path\n",
    "# \"/home/tylio/code/Project_radio_pulmo/code/radio_pulmo/models\"\n",
    "model_save_path = home / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PyTorch`\n",
    "\n",
    "### `DataLoading`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# config\n",
    "dataset_path = \"/home/tylio/code/Project_radio_pulmo/code/radio_pulmo/data/processed/covid_19_masked_tiny_500\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les transformations (optionnel, mais recommand√©)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "])\n",
    "\n",
    "# Charger les donn√©es √† partir du dossier\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "#dataset_test = datasets.ImageFolder(root='Testing', transform=transform)\n",
    "\n",
    "# mean and std for normalization\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "mean, std = get_mean_std(loader)\n",
    "\n",
    "# D√©finir les transformations (optionnel, mais recommand√©)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    # transforms.RandomRotation(10), # Rotates the images upto Max of 10 Degrees\n",
    "    # transforms.RandomHorizontalFlip(p=0.4), #Performs Horizantal Flip over images \n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "    transforms.Normalize(mean=mean, std=std)  # normalize\n",
    "])\n",
    "\n",
    "# Re-Charger les donn√©es avec la nouvelle transformation\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Normalization and data augmentation`\n",
    "\n",
    "Test en ajoutant aussi un resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finir les transformations (optionnel, mais recommand√©)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "])\n",
    "\n",
    "# Charger les donn√©es √† partir du dossier\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "#dataset_test = datasets.ImageFolder(root='Testing', transform=transform)\n",
    "\n",
    "# mean and std for normalization\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "mean_nums, std_nums = get_mean_std(loader)\n",
    "\n",
    "# D√©finir les transformations (optionnel, mais recommand√©)\n",
    "data_transforms = {\n",
    "    \"train\":transforms.Compose([\n",
    "        transforms.Resize((150,150)), #Resizes all images into same dimension\n",
    "        transforms.RandomRotation(10), # Rotates the images upto Max of 10 Degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.4), #Performs Horizantal Flip over images \n",
    "        transforms.ToTensor(), # Coverts into Tensors\n",
    "        transforms.Normalize(mean = mean_nums, std=std_nums)]), # Normalizes\n",
    "\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((150,150)),\n",
    "        transforms.CenterCrop(150), #Performs Crop at Center and resizes it to 150x150\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_nums, std = std_nums)\n",
    "    ])}\n",
    "\n",
    "# Re-Charger les donn√©es avec la nouvelle transformation\n",
    "def load_split_train_test(datadir, data_transforms, valid_size = .2):\n",
    "    train_data = datasets.ImageFolder(\n",
    "        datadir,\n",
    "        transform=data_transforms['train']\n",
    "        ) #Picks up Image Paths from its respective folders and label them\n",
    "    test_data = datasets.ImageFolder(\n",
    "        datadir,\n",
    "        transform=data_transforms['val']\n",
    "        )\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    dataset_size = {\"train\":len(train_idx), \"val\":len(test_idx)}\n",
    "    train_sampler = SubsetRandomSampler(train_idx) # Sampler for splitting train and val images\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=8) # DataLoader provides data from traininng and validation in batches\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=8)\n",
    "    return trainloader, testloader, dataset_size\n",
    "\n",
    "dataloader_train, dataloader_test, dataset_size = load_split_train_test(dataset_path, data_transforms, .2)\n",
    "dataloaders = {\"train\":dataloader_train, \"val\":dataloader_test}\n",
    "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "class_names = dataloader_train.dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Splitting data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset 80%, 20% --> [0.8, 0.2]\n",
    "dataset_train, dataset_test = torch.utils.data.random_split(full_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader object\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Baseline Model definition from hugging face`\n",
    "\n",
    "[Hugging face models image classification sort by downloads](https://huggingface.co/models?pipeline_tag=image-classification&sort=downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test ResNet-50\n",
    "\n",
    "[ResNet50_hugging_face](https://huggingface.co/microsoft/resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "# import torchgen\n",
    "\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# freeze (false) or unfreeze params (True):\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Adaptation to our 4 classes by changing the final layer\n",
    "num_labels = 4\n",
    "model.num_labels = num_labels\n",
    "# model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_labels)\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test VGG16\n",
    "\n",
    "[vgg16.tv_in1k_hugging_face](https://huggingface.co/timm/vgg16.tv_in1k) --> trained on ImageNet 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model('vgg16.tv_in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.features[-3].out_channels\n",
    "print(model.features[-3])\n",
    "model.head.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.head.fc) --> Linear(in_features=4096, out_features=1000, bias=True)\n",
    "model.head.fc = torch.nn.Linear(4096, 4)\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze (false) or unfreeze params (True):\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Adaptation to our 4 classes by changing the final layer\n",
    "num_labels = 4\n",
    "model.num_labels = num_labels\n",
    "# model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
    "# model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_labels)\n",
    "\n",
    "#device = \"cuda\"\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Baseline Model definition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = \"cuda\"\n",
    "model = nn.Sequential(\n",
    "   nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3), # output 16, 254, 254\n",
    "   nn.MaxPool2d(kernel_size=2), # output 16, 127, 127\n",
    "   nn.ReLU(),\n",
    "    \n",
    "   nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3), # 32, 125, 125\n",
    "   nn.ReLU(),\n",
    "   nn.MaxPool2d(kernel_size=2), # output 32, 62, 62\n",
    "    \n",
    "   nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # output  64, 60, 60\n",
    "   nn.ReLU(),\n",
    "   nn.MaxPool2d(kernel_size=2), # output 64, 30, 30\n",
    "    \n",
    "   nn.Flatten(),\n",
    "   nn.Linear(64 * 30 * 30, 64), # on pr√©cise ici la dim finale --> 64, 30, 30\n",
    "   nn.ReLU(),\n",
    "   nn.Linear(64, 4)\n",
    "\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,256,256), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Loss function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader_train))\n",
    "\n",
    "# D√©finir la fonction de perte\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "y_pred = model(X_batch.to(device))\n",
    "\n",
    "criterion(y_pred, y_batch.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fitting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "epochs = 10\n",
    "\n",
    "# D√©finition de l'optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Dans ce mode certaines couches du mod√®le agissent diff√©remment\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    # Barre de progression\n",
    "    progress_bar = tqdm(\n",
    "            dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=True, disable=False\n",
    "        )\n",
    "    \n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        # Batch de donn√©es\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # Device\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Gradient mis 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calcul de pr√©diction\n",
    "        y_pred = model(X_batch.to(torch.float32))\n",
    "\n",
    "        # Calcul de la fonction de perte\n",
    "        loss =  criterion(y_pred, y_batch) #torch.mean(torch.abs(y_pred- y_batch.to(torch.float32)))#\n",
    "        # Backpropagation : calculer le gradient de la loss en fonction de chaque couche\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clipper le gradient entre 0 et 1 pour plus de stabilit√©\n",
    "        #  torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Descente de gradient : actualisation des param√®tres\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"training_loss\": \"{:.3f}\".format(loss_total/(i+1))}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    # Passer le mod√®le en √©valuation\n",
    "    model.eval()\n",
    "    # Calculer la loss totale\n",
    "    loss_val_total = 0\n",
    "    # Stocker les pr√©dictions et les vraies valeurs.\n",
    "    predictions, true_vals = [], []\n",
    "    for batch in dataloader_val:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            # Pr√©diction du mod√®le pour un batch donn√©\n",
    "            y_pred = model(X_batch.to(torch.float32))\n",
    "        # Calcul de la fonction de perte pour l'utiliser comme une m√©trique\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        # Cummuler la fonction de perte de tous les lots de donn√©es.\n",
    "        loss_val_total += loss.item()\n",
    "        # Enregistrer les pr√©dictions pour les utiliser plus tard\n",
    "        predictions.extend(y_pred.detach().cpu().numpy())\n",
    "        # Enregistrer les vraies valeurs pour les utiliser plus tard\n",
    "        true_vals.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Loss du jeu de donn√©es val\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    # Ensemble des pr√©dictions du jeu de donn√©es\n",
    "    predictions = np.array(predictions)\n",
    "    # Id prediction\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    # Ensemble des vraies valeurs du jeu de donn√©es\n",
    "    true_vals = np.array(true_vals)\n",
    "    return {\"loss\":loss_val_avg, \"accuracy\":accuracy_score(true_vals, predictions)}\n",
    "\n",
    "\n",
    "metrics = evaluate(dataloader_test)\n",
    "\n",
    "print(f\"Loss: {metrics['loss']}\")\n",
    "print(f\"Accuracy : {metrics['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Confusion matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "on_cuda = True # computed using cuda\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in dataloader_test:\n",
    "    if on_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = folder_to_process\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], \n",
    "                     index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (6,4))\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DenseNet-121 architecture`\n",
    "\n",
    "Using tuto on kaggle: [covid-19-detection-pytorch-tutorial](https://www.kaggle.com/code/arunrk7/covid-19-detection-pytorch-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Model creation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = folder_to_process\n",
    "device=\"cuda\"\n",
    "\n",
    "def CNN_Model(pretrained=True):\n",
    "    model = models.densenet121(weights=pretrained) # Returns Defined Densenet model with weights trained on ImageNet\n",
    "    num_ftrs = model.classifier.in_features # Get the number of features output from CNN layer\n",
    "    model.classifier = nn.Linear(num_ftrs, len(class_names)) # Overwrites the Classifier layer with custom defined layer for transfer learning\n",
    "    model = model.to(device) # Transfer the Model to GPU if available\n",
    "    return model\n",
    "\n",
    "model = CNN_Model(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Every model Training and evaluation`\n",
    "\n",
    "La partie ci-dessous contient le code pour le training et evaluation du model contenue dans la variable `model` avec le dataset d'entrainement de validation dans le dict `dataloaders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Criterion & Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy loss)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Specify optimizer which performs Gradient Descent\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Training function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\"train\":dataloader_train,\n",
    "               \"val\":dataloader_test}\n",
    "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "\n",
    "metrics = {\n",
    "    \"acc\":[],\n",
    "    \"val_acc\":[],\n",
    "    \"loss\":[],\n",
    "    \"val_loss\":[],\n",
    "}\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            current_kappa = 0\n",
    "            val_kappa = list()\n",
    "\n",
    "            for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # We need to zero the gradients in the Cache.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Time to carry out the forward training poss\n",
    "                # We only need to log the loss stats if we are in training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                # We want variables to hold the loss statistics\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "                val_kappa.append(cohen_kappa_score(preds.cpu().numpy(), labels.data.cpu().numpy()))\n",
    "\n",
    "            epoch_loss = current_loss / data_sizes[phase]\n",
    "            epoch_acc = current_corrects.double() / data_sizes[phase]\n",
    "\n",
    "            if phase == 'val':\n",
    "                epoch_kappa = np.mean(val_kappa)\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} | {phase} Accuracy: {epoch_acc:.4f} | Kappa Score: {epoch_kappa:.4f}')\n",
    "                metrics[\"acc\"].append(float(epoch_acc))\n",
    "                metrics[\"loss\"].append(float(epoch_loss))\n",
    "            else:\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} | {phase} Accuracy: {epoch_acc:.4f}')\n",
    "                metrics[\"val_acc\"].append(float(epoch_acc))\n",
    "                metrics[\"val_loss\"].append(float(epoch_loss))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_since = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_since // 60, time_since % 60))\n",
    "    print('Best val loss: {:.4f}'.format(best_loss))\n",
    "\n",
    "    # Now we'll load in the best model weights and return it\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Visual functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class_names = folder_to_process\n",
    "\n",
    "#Statistics Based on ImageNet Data for Normalisation\n",
    "mean_nums = [mean, mean, mean]\n",
    "std_nums = [std, std, std]\n",
    "\n",
    "def imshow(inp, size =(30,30), title=None, normalized=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalized:\n",
    "        mean = mean_nums\n",
    "        std = std_nums\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, size=30)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_handeled = 0\n",
    "    ax = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_handeled += 1    \n",
    "                ax = plt.subplot(num_images//2, 2, images_handeled)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('Actual: {} predicted: {}'.format(class_names[labels[j].item()],class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j], (5,5))\n",
    "\n",
    "                if images_handeled == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "base_model = train_model(model, criterion, optimizer, exp_lr_scheduler, dataloaders, num_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Saving`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path / \"pytorch/dense121_normalized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Loading`\n",
    "\n",
    "See: [PyTorch saving_loading_models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(pretrained=True)\n",
    "model.load_state_dict(torch.load(model_save_path / \"pytorch/dense121_normalized.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Eval and visualisation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(base_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Accuracy and loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use metrics dict from train function\n",
    "\n",
    "nb_epochs = 10\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "# Courbe du score de test du r√©seau Dense 121\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"acc\"], \n",
    "         label = 'acc Dense121',\n",
    "         color = 'blue')\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"val_acc\"],\n",
    "         label = 'val_acc Dense121',\n",
    "         color = 'red')\n",
    "# Labels des axes\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "# Affichage de la l√©gende\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# Courbe du score de test du r√©seau Dense 121\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"loss\"], \n",
    "         label = 'loss Dense121',\n",
    "         color = 'blue')\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"val_loss\"],\n",
    "         label = 'val_loss Dense121',\n",
    "         color = 'red')\n",
    "\n",
    "# Labels des axes\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# Affichage de la l√©gende\n",
    "plt.legend()\n",
    "# Affichage de la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Confusion Matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "on_cuda = True # computed using cuda\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in dataloader_test:\n",
    "    if on_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = folder_to_process\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(100*cf_matrix / np.sum(cf_matrix, axis=1)[:, None], \n",
    "                     index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (6,4))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('DenseNet121 Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Hugging Face model Training and evaluation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "#dataset_path = \"/home/processed/covid_19_masked_tiny_500\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=dataset_path)\n",
    "\n",
    "# Initialize the processor for resizing and normalization\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# Define a preprocessing function\n",
    "def preprocess(batch):\n",
    "    # Process each image in the batch\n",
    "    images = []\n",
    "    for image in batch[\"image\"]:\n",
    "        # Convert image to RGB if it's grayscale\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        images.append(image)\n",
    "        \n",
    "    # Process images with the processor to resize and normalize\n",
    "    batch[\"pixel_values\"] = processor(images=images, size=256)[\"pixel_values\"]\n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Verif\n",
    "# print(dataset_train[0][\"image\"])\n",
    "\n",
    "# Splitting the dataset into 80% train and 20% test\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Access the train and test splits\n",
    "dataset_train = split_dataset[\"train\"]\n",
    "dataset_test = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hyperparameters\n",
    "\n",
    "Using [transformers/training tutorial](https://huggingface.co/docs/transformers/training)\n",
    "\n",
    "Create a [TrainingArguments](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments) class which contains all the hyperparameters you can tune as well as flags for activating different training options.\n",
    "\n",
    "With 'eval_strategy' parameter in your training arguments to report the evaluation metric at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    )\n",
    "\n",
    "backup_params = \"\"\"\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "[Trainer](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) does not automatically evaluate model performance during training. You‚Äôll need to pass Trainer a function to compute and report metrics. The [ü§ó Evaluate](https://huggingface.co/docs/evaluate/index) library provides a simple [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) function you can load with the evaluate.load (see this [quicktour](https://huggingface.co/docs/evaluate/a_quick_tour) for more information) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer object\n",
    "\n",
    "Create a [Trainer](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) object with your model, training arguments, training and test datasets, and evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recup max prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Step 1: Get predictions\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Step 2: Compute confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset_test.features[\"label\"].names)\n",
    "\n",
    "# Step 3: Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
